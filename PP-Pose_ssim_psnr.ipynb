{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70a5ee57-fc53-407d-b43a-615ade6eb702",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "from torchjpeg import dct\n",
    "import torch\n",
    "import torch.fft\n",
    "from torch.nn import functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from pycocotools.coco import COCO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51488ef5-bb10-4618-aee3-0d5ad61e884d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def dct_transform(x, chs_remove=None, chs_pad=False,\n",
    "                  size=8, stride=8, pad=0, dilation=1, ratio=8, chs_select = 9):\n",
    "    \"\"\"\n",
    "        Transform a spatial image into its frequency channels.\n",
    "        Prune low-frequency channels if necessary.\n",
    "    \"\"\"\n",
    "\n",
    "    # assert x is a (3, H, W) RGB image\n",
    "    assert x.shape[1] == 3\n",
    "\n",
    "    # convert the spatial image's range into [0, 1], recommended by TorchJPEG\n",
    "    x = x / 255.0\n",
    "\n",
    "    # up-sample\n",
    "    x = F.interpolate(x, scale_factor=ratio, mode='bilinear', align_corners=True)\n",
    "\n",
    "    # convert to the YCbCr color domain, required by DCT\n",
    "    x = x * 255\n",
    "    x = dct.to_ycbcr(x)\n",
    "    x = x - 128\n",
    "\n",
    "    # perform block discrete cosine transform (BDCT)\n",
    "    b, c, h, w = x.shape\n",
    "    h_block = h // stride\n",
    "    w_block = w // stride\n",
    "    x = x.view(b * c, 1, h, w)\n",
    "    x = F.unfold(x, kernel_size=(size, size), dilation=dilation, padding=pad, stride=(stride, stride))\n",
    "    x = x.transpose(1, 2)\n",
    "    x = x.view(b, c, -1, size, size)\n",
    "    x_freq = dct.block_dct(x)\n",
    "    x_freq = x_freq.view(b, c, h_block, w_block, size * size).permute(0, 1, 4, 2, 3)\n",
    "\n",
    "    # prune channels\n",
    "    if chs_remove is not None:\n",
    "        channels = list(set([i for i in range(64)]) - set(chs_remove))\n",
    "        #channels = [0, 1, 2, 3, 8, 9, 10, 16, 17, 24]\n",
    "        selected_channels = random.sample(channels, chs_select)\n",
    "        if not chs_pad:\n",
    "            # simply remove channels\n",
    "            x_freq = x_freq[:, :, selected_channels, :, :]\n",
    "        else:\n",
    "            # pad removed channels with zero, helpful for visualization\n",
    "            x_freq[:, :, channels] = 0\n",
    "\n",
    "    # stack frequency channels from each color domain\n",
    "    x_freq = x_freq.reshape(b, -1, h_block, w_block)\n",
    "\n",
    "    return x_freq\n",
    "\n",
    "def idct_transform(x, size=8, stride=8, pad=0, dilation=1, ratio=8):\n",
    "    \"\"\"\n",
    "        The inverse of DCT transform.\n",
    "        Transform frequency channels (must be 192 channels, can be padded with 0) back to the spatial image.\n",
    "    \"\"\"\n",
    "    b, c, h, w = x.shape\n",
    "    expanded_x = torch.zeros(b, 192, h, w, dtype=x.dtype, device=x.device)\n",
    "    for i in range(3):  \n",
    "        expanded_x[:, i*64:(i*64)+(c//3), :, :] = x[:, i*(c//3):(i+1)*(c//3), :, :]\n",
    "    # print(expanded_x.shape)\n",
    "    \n",
    "    b, c, h, w = expanded_x.shape\n",
    "    x = expanded_x.view(b, 3, 64, h, w)\n",
    "    x = x.permute(0, 1, 3, 4, 2)\n",
    "    x = x.view(b, 3, h * w, 8, 8)\n",
    "    x = dct.block_idct(x)\n",
    "    x = x.view(b * 3, h * w, 64)\n",
    "    x = x.transpose(1, 2)\n",
    "    x = F.fold(x, output_size=(h * ratio, w * ratio),\n",
    "               kernel_size=(size, size), dilation=dilation, padding=pad, stride=(stride, stride))\n",
    "    x = x.view(b, 3, h * ratio, w * ratio)\n",
    "    x = x + 128\n",
    "    x = dct.to_rgb(x)\n",
    "    #x = x / 255\n",
    "    x = F.interpolate(x, scale_factor=1 / ratio, mode='bilinear', align_corners=True)\n",
    "    #x = x.clamp(min=0.0, max=1.0)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9a9eaf3-eb6c-495b-84c8-51267bfdf76c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_batch_ssim_psnr(torch_img, numpy_img_set):\n",
    "    \"\"\"\n",
    "    Compute the batch-wise SSIM and PSNR metrics.\n",
    "    :param torch_img: The torch tensor image.\n",
    "    :param numpy_img_set: The numpy array image set.\n",
    "    :return: The batch-wise SSIM mean and PSNR mean metrics.\n",
    "    \"\"\"\n",
    "    ssim_batch = []\n",
    "    psnr_batch = []\n",
    "    torch_img = torch_img.cpu()\n",
    "    torch_img = torch_img.numpy()\n",
    "    torch_img = torch_img.transpose((0, 2, 3, 1))\n",
    "    for i in range(len(numpy_img_set)):\n",
    "        psnr_value = psnr(torch_img[i], numpy_img_set[i], data_range=255)\n",
    "        psnr_batch.append(psnr_value)\n",
    "        for j in range(len(numpy_img_set[0])):\n",
    "            ssim_index = ssim(numpy_img_set[i][j], torch_img[i][j], channel_axis=-1, data_range=255.0)\n",
    "            ssim_batch.append(ssim_index)\n",
    "    ssim_batch = np.array(ssim_batch)\n",
    "    psnr_batch = np.array(psnr_batch)\n",
    "    return np.mean(ssim_batch), np.mean(psnr_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12f3362f-81aa-42de-9263-fa39ae59fd69",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.30s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "val_dataset = \"/root/autodl-tmp/coco2017/val2017\"\n",
    "annFile = '/root/autodl-tmp/coco2017/annotations/person_keypoints_val2017.json'\n",
    "#img_sets = os.listdir(path)\n",
    "device = torch.device('cuda:0')\n",
    "transform = transforms.ToTensor()\n",
    "test_set = []\n",
    "test_ssim = []\n",
    "test_psnr = []\n",
    "temp = 0\n",
    "\n",
    "# COCO API\n",
    "coco = COCO(annFile)\n",
    "\n",
    "# get all image ID\n",
    "image_ids = coco.getImgIds()\n",
    "\n",
    "# get every image id\n",
    "image_info = coco.loadImgs(image_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1eb0696-d8c1-4cf6-9380-8f20e0e33905",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.32202406817008766 10.804399690500794\n",
      "0.43923410647965133 13.192959391409044\n",
      "0.4990015243927739 10.975258889247286\n",
      "0.43624621292841814 12.529504631558147\n",
      "0.3992937911145037 11.116746866627945\n",
      "0.37758064479892134 11.640122438508508\n",
      "0.48475095213178016 12.977788729118709\n",
      "0.35631677925766025 11.35582164749406\n",
      "0.32278947595087204 10.532536467544766\n",
      "0.4507062023642441 10.907366532492302\n",
      "0.3828182632514336 10.706525900113887\n",
      "0.3514391153527673 10.60919645494293\n",
      "0.4200334066812093 10.939692961055353\n",
      "0.3199174919563026 10.925025663005844\n",
      "0.42851695256532174 12.179270188143317\n",
      "0.42971394957730435 10.65957088805165\n",
      "0.3838379564279494 10.531025455492852\n",
      "0.38990591986277734 11.32853242614673\n",
      "0.376727841708293 10.406993443998322\n",
      "0.3864319481955223 11.100305765558804\n",
      "0.3950127384345212 12.337731399202946\n",
      "0.38400018777630673 11.898691562040923\n",
      "0.4092148318101783 12.068269217182886\n",
      "0.36386880239966835 11.113905705588868\n",
      "0.35568918644841574 10.628210967246341\n",
      "val_s9_ssim:  0.3867971773640353 val_s9_psnr:  11.266810955290511\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(image_info)):\n",
    "    img_path = os.path.join(val_dataset + \"/\" + image_info[i]['file_name'])\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.resize(img, (256, 256))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    test_set.append(img)\n",
    "    temp = temp + 1\n",
    "    if temp % 8 == 0 or i == len(image_info)-1:\n",
    "        images = torch.stack([transform(img).to(device) for img in test_set])\n",
    "        #images = dct_transform(images, chs_remove = [0, 1, 2, 3, 8, 9, 10, 16, 17, 24, 39, 46, 47, 53, 54, 55, 60, 61, 62, 63])\n",
    "        images = dct_transform(images, chs_remove = [0, 1, 2, 3, 8, 9, 10, 16, 17, 24])\n",
    "        img_spat = idct_transform(images)\n",
    "        a, b = compute_batch_ssim_psnr(img_spat, test_set)\n",
    "        if temp % 200 == 0:\n",
    "            print(a, b)\n",
    "        test_ssim.append(a)\n",
    "        test_psnr.append(b)\n",
    "        test_set = []\n",
    "\n",
    "test_ssim = np.array(test_ssim)\n",
    "test_psnr = np.array(test_psnr)\n",
    "print(\"val_s9_ssim: \", np.mean(test_ssim), \"val_s9_psnr: \", np.mean(test_psnr))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
